{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_wQl5fRT9Wi"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Name : Aditya Pradip Kulkarni.\n",
    "\n",
    "Date : 23/10/2022\n",
    "\n",
    "\n",
    "Q1 . What are the advantages of a CNN over a fully connected deep neural network for image classification?\n",
    "\n",
    "Ans : \n",
    "        1. In fully connected deep neural network the number of parameters taken into consideration are more as compared to Convolution Neural network. In \n",
    "           fully connected neural network a single neuron is fully connected to its precedding neurons and the neurons ahead of it due to which the number of parameters are more.\n",
    "        2. When compared to fully connected network, in a Convolution neural network the dimensions of data(image data) goes on reducing as the convulition operations are performed.\n",
    "        3. A CNN is designed in a way that assumes the data fed to it is in form of images which makes it easy to encode the image and later process on it.\n",
    "\n",
    "Q2. Why would you want to add a max pooling layer rather than a convolutional layer with the same stride?\n",
    "\n",
    "Ans : \n",
    "      1. Max pooling layer will reduce the number of parameters to be taken for computation from the image data which will reduce the computation cost as well.\n",
    "\n",
    "Q3. When would you want to add a local response normalization layer?\n",
    "\n",
    "Ans : \n",
    "      1. This layers is useful when working with RELU activation, as they have unbounded activation so in order to normalize them we use local response layer after convolution layer\n",
    "         to normalize the inputs prior to sending them ahead to activation nodes.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7RIOJXGJpALw",
    "outputId": "ab50e2a0-8ff6-452b-9dad-c5d3294addda"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train original shape (60000, 28, 28)\n",
      "y_train original shape (60000,)\n",
      "X_test original shape (10000, 28, 28)\n",
      "y_test original shape (10000,)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 594,922\n",
      "Trainable params: 594,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:132: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [==============================] - 159s 169ms/step - loss: 0.2028 - accuracy: 0.9362 - val_loss: 0.0329 - val_accuracy: 0.9896\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 157s 167ms/step - loss: 0.0631 - accuracy: 0.9804 - val_loss: 0.0318 - val_accuracy: 0.9899\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 152s 162ms/step - loss: 0.0475 - accuracy: 0.9860 - val_loss: 0.0256 - val_accuracy: 0.9924\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 155s 165ms/step - loss: 0.0401 - accuracy: 0.9877 - val_loss: 0.0206 - val_accuracy: 0.9943\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 155s 166ms/step - loss: 0.0350 - accuracy: 0.9894 - val_loss: 0.0258 - val_accuracy: 0.9911\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.0258 - accuracy: 0.9911\n",
      "\n",
      "Test accuracy:  0.991100013256073\n",
      "313/313 [==============================] - 6s 19ms/step\n",
      "      Actual                                        Predictions\n",
      "0          7  [9.866584e-10, 2.1898514e-07, 5.1982417e-05, 1...\n",
      "1          2  [1.6988574e-08, 2.4531253e-06, 0.9999955, 2.57...\n",
      "2          1  [4.68002e-06, 0.99979305, 1.5998638e-05, 7.908...\n",
      "3          0  [0.99973905, 5.9636506e-08, 1.2663667e-06, 5.7...\n",
      "4          4  [3.6282452e-10, 6.08486e-08, 5.300167e-08, 8.6...\n",
      "...      ...                                                ...\n",
      "9995       2  [1.2161125e-10, 3.3514203e-07, 0.9999915, 3.01...\n",
      "9996       3  [2.9178888e-09, 1.1784274e-06, 3.979879e-06, 0...\n",
      "9997       4  [1.7343445e-12, 1.6562527e-08, 8.6577334e-10, ...\n",
      "9998       5  [3.6175743e-10, 3.2894345e-12, 7.764121e-11, 5...\n",
      "9999       6  [9.874052e-06, 3.1345557e-08, 8.0233265e-05, 5...\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nQ5. Make comments on your results in step 4. \\n\\nAns : 1. The validation loss is decreasing so no issue of over-fitting.\\n      2. The categorical_crossentropy loss is decreasing across the epocs 1 - 5, at 5th epoch it is 0.0365. Model performs good with accuracy : 0.9891\\n      3. The dimensions of the data when data was fed to network to 1st convolution layer : \\n      ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n          Conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \\n                                                                 \\n          activation_6 (Activation)   (None, 26, 26, 32)        0         \\n                                                                 \\n          conv2d_5 (Conv2D)           (None, 24, 24, 32)        9248      \\n                                                                 \\n          activation_7 (Activation)   (None, 24, 24, 32)        0         \\n                                                                 \\n          max_pooling2d_2 (MaxPooling  (None, 12, 12, 32)       0         \\n          2D)  \\n      ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++                                                           \\n          conv2d_6 (Conv2D)           (None, 10, 10, 64)        18496     \\n         \\n          activation_8 (Activation)   (None, 10, 10, 64)        0         \\n                                                                          \\n          conv2d_7 (Conv2D)           (None, 8, 8, 64)          36928     \\n                                                                          \\n          activation_9 (Activation)   (None, 8, 8, 64)          0         \\n                                                                          \\n          max_pooling2d_3 (MaxPooling  (None, 4, 4, 64)         0         \\n          2D)       \\n          \\n> > Here the dimensions of the data goes on reducing as the data is processed through the 1st layer of 1st : Conv-Activation-Conv-Batch-normalization-Activation-MaxPooling\\n    to 2nd : Conv-Activation-Conv-Activation-MaxPooling. This is due to max-pooling layer extracts the required pixels having high value of concentration and its neighbours.                                                    \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q4 . Test the code with MNIST data and show model accuracy.\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "np.random.seed(25)\n",
    "\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"y_train original shape\", y_train.shape)\n",
    "print(\"X_test original shape\", X_test.shape)\n",
    "print(\"y_test original shape\", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.title('Class '+ str(y_train[0]))\n",
    "\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "\n",
    "\n",
    "number_of_classes = 10\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "\n",
    "y_train[0], Y_train[0]\n",
    "\n",
    "\n",
    "# Three steps to Convolution\n",
    "# 1. Convolution\n",
    "# 2. Activation\n",
    "# 3. Pooling\n",
    "# Repeat Steps 1,2,3 for adding more hidden layers\n",
    "\n",
    "# 4. After that make a fully connected network\n",
    "# This fully connected network gives ability to the CNN\n",
    "# to classify the samples\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "BatchNormalization()\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "\n",
    "# model.add(Convolution2D(10,3,3, border_mode='same'))\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    " height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "\n",
    "\n",
    "\n",
    "train_generator = gen.flow(X_train, Y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n",
    "\n",
    "\n",
    "\n",
    "# model.fit(X_train, Y_train, batch_size=128, nb_epoch=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5, \n",
    " validation_data=test_generator, validation_steps=10000//64)\n",
    "\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print()\n",
    "print('Test accuracy: ', score[1])\n",
    "\n",
    "\n",
    "\n",
    "redict_x=model.predict(X_test) \n",
    "\n",
    "predictions = list(redict_x)\n",
    "actuals = list(y_test)\n",
    "\n",
    "sub = pd.DataFrame({'Actual': actuals, 'Predictions': predictions})\n",
    "print(sub)\n",
    "#sub.to_csv('./output_cnn.csv', index=False)\n",
    "\n",
    "\"\"\"\n",
    "Q5. Make comments on your results in step 4. \n",
    "\n",
    "Ans : 1. The validation loss is decreasing so no issue of over-fitting.\n",
    "      2. The categorical_crossentropy loss is decreasing across the epocs 1 - 5, at 5th epoch it is 0.0365. Model performs good with accuracy : 0.9891\n",
    "      3. The dimensions of the data when data was fed to network to 1st convolution layer : \n",
    "      ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "          Conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
    "                                                                 \n",
    "          activation_6 (Activation)   (None, 26, 26, 32)        0         \n",
    "                                                                 \n",
    "          conv2d_5 (Conv2D)           (None, 24, 24, 32)        9248      \n",
    "                                                                 \n",
    "          activation_7 (Activation)   (None, 24, 24, 32)        0         \n",
    "                                                                 \n",
    "          max_pooling2d_2 (MaxPooling  (None, 12, 12, 32)       0         \n",
    "          2D)  \n",
    "      ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++                                                           \n",
    "          conv2d_6 (Conv2D)           (None, 10, 10, 64)        18496     \n",
    "         \n",
    "          activation_8 (Activation)   (None, 10, 10, 64)        0         \n",
    "                                                                          \n",
    "          conv2d_7 (Conv2D)           (None, 8, 8, 64)          36928     \n",
    "                                                                          \n",
    "          activation_9 (Activation)   (None, 8, 8, 64)          0         \n",
    "                                                                          \n",
    "          max_pooling2d_3 (MaxPooling  (None, 4, 4, 64)         0         \n",
    "          2D)       \n",
    "          \n",
    "> > Here the dimensions of the data goes on reducing as the data is processed through the 1st layer of 1st : Conv-Activation-Conv-Batch-normalization-Activation-MaxPooling\n",
    "    to 2nd : Conv-Activation-Conv-Activation-MaxPooling. This is due to max-pooling layer extracts the required pixels having high value of concentration and its neighbours.                                                    \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
